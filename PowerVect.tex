\section{Power Vector Spaces}
\label{power}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "Quant"
%%% End: 


%%\renewcommand{\wp}{\mathcal{P}}
For every set $X$, $V_X$ denotes the vector space free over $X$, i.e. where
vectors are linear combinations $\sum_{x \in X} \alpha_x\ket{x}$. The
assignment, $V$, of a vector space to a set extends to a functor $V : \Set
\to \FdVect$ which takes a function $f : X \to Y$ to the linear map
$\sum_{x \in X} \alpha_x \ket{x} \mapsto \sum_{x \in X} \alpha_x f(\ket{x})$. 
Note that every finite vector space is, by definition, free over a
finite set --- the cardinal of its dimension. 

Let $\wp X$ denote the powerset of $X$.  We lift
$\wp$ from $\Set$ to $\FdVect$ along $V$ by
defining $\wp V_X = V_{\wp X}$, and call $\wp V_X$ the \emph{power
(vector) space} of $V_X$. Less formally, the basis of $\wp A$ is the
powerset of the basis of $A$.

For example, the basis of $\wp V_2$ is $\{\emptyset, \{0\}, \{1\},
\{0,1\}\}$, and an example of a vector is $\alpha_0
\ket{\{0\}}+\alpha_{0,1}\ket{\{0,1\}}$. 

\begin{quote}{\footnotesize
But wait a minute! There already are mixtures in vector spaces and now
we are introducing set-like mixtures to the basis. For instance,
shouldn't there be some relation between vectors $\ket{0} + \ket{1}$
and $\ket{\{0,1\}}$? Well, no if we want to have a precise control
over quantification.}
\end{quote}

% Formally, let $\eta : V_X \to V_{\wp X} = \wp V_X$ be the inclusion
% defined by $\ket{i} \mapsto \ket{\{i\}}$ for each $i \in X$. And let $\epsilon : \wp V_X
% \to V_X$ be defined by $\ket{I} \mapsto \sum_{i\in I} \ket{i}$, for
% each $I \subseteq X$. Then $\epsilon \eta = 1$ and the quotient 
% $V_{\wp X}/_\sim$ along family equations of the form $\ket{I} \sim \sum_{i\in
%   I} \ket{i}$, $I \subseteq X$, is clearly isomorphic to $V_X$. 

For the purpose of this paper, a vector in $A$ is taken to a vector in
${\cal P}A$ via $\ket{i} \mapsto \ket{\{ i \}}$. This means an
arbitrary vector $\sum_{x}\alpha_x\ket{x}$ is taken to
$\sum_{x}\alpha_x\ket{\{x\}}$. For instance, for $\{x , x'\} \subseteq X$,
$\mathcal{P}(\ket{x} + \ket{x'}) = \ket{\{x\}} + \ket{\{x'\}} \neq
\ket{\{ x,x' \}}$. As soon as we impose such equations, $\wp V_X$
becomes equal to $V_X$.  WHY?

If we impose such an equality we will have
\[
\ket{\{x\}} +  \ket{\{x'\}} = \ket{\{x,x'\}}
\]
The right hand side is not an element of $V_X$ because it has the set $\{x,x'\}$ as a basis vector.  So I do not see why do you say there will be a collapse. 


\textbf{OR:} In a vector space generated by $\wp X$ with equations
(i.e. not freely generated) of the form $\ket{x_i}+\ket{x_j} =
\ket{\{x_i,x_j\}}$, forall $i\neq j, i,j \leq n$, the vectors
$\ket{p}, p\subseteq X$ no longer form a basis as they are not
independent. And I'm pretty sure that up to associativity and
commutativity, the basis is precisely just $\ket{\{x\}}, x\in X$. I.e. the
vector space is isomorphic to $V_X$.
I even have a categorical proof somewhere on paper, but it is just
that. 

Here is an example: take a vector $v = \ket{x} + 2\ket{x,y}$ over
the basis $\{x,y\}$ with 
\begin{equation}\label{eq:1}
\ket{x} + \ket{y} =\ket{x,y}
\end{equation}
%
Call the space $W$.
I'm dropping the curly brackets inside kets, so writing
just $\ket{x}$ instead of $\ket{\{x\}}$, etc.  Then
\begin{align*}
v &= \ket{x} + 2\ket{x,y} \\
& = \ket{x} + 2(\ket{x} + \ket{y}) & \text{\textit{by \eqref{eq:1}}}\\
& = 3\ket{x} + \ket{y}
\end{align*}
%
So $v$ in $W$ is an element of $V_{\{x,y\}}$. The other direction is
just reading the equations bottom up. So $W \cong V_{\{x,y\}}$. 

Well, to be absolutely precise we also need an equation of the form
$\ket{\emptyset}+\ket{X} = \ket{X}$, simply because $\emptyset$
doesn't fit the scheme above. In the finite case, the nullary and the
binary case is enough. In the general case, one wants $\ket{X}+\ket{Y}
= \ket{X \cup Y}$. That equates $\emptyset$ with the $0$-vector, and a
linear combination with subset. But maybe it's not as much as a
problem as a feature. It is in line with the intution that vectors are
like (generalised) sets. I'm looking into it. 

Equating set union with linear combination would mean that existential
and univerasal quantification are the same, because a union of
nonempty subsets of $X$ is $X$. A different quantifier is ``none''
because in terms of generalised quantifiers, its semantics is $\{
\emptyset \}$, i.e. just the zero vector, i.e. ``none'' = ``not some''
= ``not all''. Any precise numbers are obviously out of question. 

I have to think about relations a bit, but it seems we get essentially
the same as in vector spaces. Because a relation $x \sim y$ and $x \sim z$
should be the same as $x \sim \{y,z\}$, otherwise we run into exactly the
same problem with $\eta$ (what is here called $\mathcal{P}$, but
$\eta$ is a better name, imho).  The only difference is sets
and functions, because functions are single valued. 

So maybe there in lies the clue: the problem is already with
Relations. But relations should be fine with universal quantifiaction,
at least. The right adjoint exists. So lets look into how
quantification is done in Rel and take it into $\FdVect$. $\Set$ is
too special, too unstructured. But also maybe this is usable, as a
nonresult. Or rather as a result showing how the distributional
setting collapses quantifiers. Seriously, if cooccurence is our
semantics, how can you expect to distinguish between ``all men sleep''
and ``some men sleep'': ``men'' and ``sleep'' coocur exactly the same
in both. (?)





\begin{quote}{\footnotesize
Given a vector space $V$ with a fixed set of basis vectors, we denote the set of its  basis vectors by $B_V$.  We define a power vector space operation as a functor on $FVect$, that is we have 
\[
{\cal P} \colon FVect \to FVect
\]
Given a vector space $V$, its power vector space ${\cal P}V$ is a vector space freely generated over the set of subsets of $B_V$.  That is, the set of basis vectors of ${\cal P}V$ is ${\cal P}(B_V)$. 

For the purpose of this paper, a vector in $V$ is taken to a vector in ${\cal P}V$ where the latter vector has brackets around its basis vectors. That is,  a vector $\sum_i C_i \ov{v}_i$ in $V$ is taken to $\sum_i C_i \{\ov{v}_i\}$ in ${\cal P}V$. 

We define a map 
\[
Det \colon V \to {\cal P}V
\]
to assign  to each vector in $V$, a vector in its power vector space
${\cal P}V$, consisting of a family of subsets of the basis vectors of
$V$.  That is, a vector $\sum_i C_i \ov{v}_i$ in $V$, is taken to
$\sum_i C_i \ov{w}_i$, where $w \subseteq B_V$. 
}\end{quote}